{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práticas Computacionais Avançadas - NLP\n",
    "\n",
    "## Extração de dados para análise do uso de compostos químicos na síntese de perovskitas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------- #\n",
    "#                                     SETUP                                    #\n",
    "# ---------------------------------------------------------------------------- #\n",
    "\n",
    "# -------------------------------- Importações ------------------------------- #\n",
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "# ------------------------ Carregando dados coletados ------------------------ #\n",
    "data = pd.read_excel(\"prvsk_data/1_to_1000.xls\")\n",
    "# --------------!!!!!!!! COLOCAR O RESTO DOS DADOS DEPOIS !!!!!!!!--------------\n",
    "corpora = [abstract for abstract in data[\"Abstract\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop words: {'and', 'haven', 'their', 'a', \"wouldn't\", 'most', 'herself', 'them', 'shan', 'been', \"shan't\", 'through', 'yourself', 'ain', 'theirs', 'had', 'weren', 'which', \"should've\", 'ours', 'should', 're', 've', 'be', 't', 'at', 'then', 'but', 'on', 'or', 'any', 'just', 'hers', 'they', 'didn', 'will', 'wasn', 'having', 'because', 'doesn', 'd', 'of', 'while', 'the', 'if', 'between', \"mustn't\", 'he', 'by', 'against', 'from', 'until', 'when', 'such', 'o', 'these', 'hasn', 'after', 'further', \"mightn't\", 'we', 'more', 'wouldn', 'his', 'ourselves', 'themselves', \"haven't\", 'during', 'isn', 'how', 'up', \"you've\", 'it', \"wasn't\", 'no', 'm', \"didn't\", 'couldn', 'under', 'did', \"hasn't\", 'needn', 'its', 'she', 'all', 'to', 'above', 'can', 'other', \"she's\", 'nor', \"isn't\", 'once', 'as', 'those', 'does', 'are', \"hadn't\", 'below', 'with', 'shouldn', 'him', 'our', 'her', 'has', 'who', 'so', \"aren't\", 'doing', 'only', 'now', 'won', 'you', 'own', 'myself', 'what', 'for', 'this', 'my', 'that', 'off', 'before', 'yourselves', 'few', \"it's\", 'yours', 'll', 'again', 'aren', 'each', 'why', \"doesn't\", 'some', 'himself', 'hadn', 'both', 'than', 'ma', 'do', 'out', \"needn't\", 'i', \"you're\", 'an', 'there', \"that'll\", 'itself', 'mightn', 'whom', 'not', 'down', \"couldn't\", \"weren't\", 'were', 'same', 'where', \"won't\", 'is', 'too', 'in', 'don', 's', 'about', \"you'll\", 'here', 'your', 'was', \"you'd\", 'have', \"don't\", 'y', \"shouldn't\", 'into', 'me', 'very', 'being', 'mustn', 'over', 'am'}\n",
      "\n",
      "['CsPbX3', 'perovskite', 'material', 'benefits', 'advanced', 'light', 'absorption', 'coefficient', 'long', 'carrier', 'lifetime', 'simple', 'preparation', 'process', 'perovskite', 'materials', 'also', 'maintains', 'excellent', 'stability']\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------- #\n",
    "#                           PRÉ-PROCESSAMENTO (NLTK)                           #\n",
    "# ---------------------------------------------------------------------------- #\n",
    "\n",
    "# ------------------ \"Tokenização\" dos corpus obtidos (NLTK) ----------------- #\n",
    "tokens = []\n",
    "\n",
    "for corpus in corpora:\n",
    "    doc = nltk.tokenize.word_tokenize(corpus)\n",
    "    tokens.extend(doc)\n",
    "\n",
    "# ------------------ Removendo stop-words e pontuação (NLTK) ----------------- #\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "print(f'Stop words: {stop_words}')\n",
    "print()\n",
    "\n",
    "tokens = [token for token in tokens if (not token in stop_words and token.isalnum())]\n",
    "\n",
    "print(tokens[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('However', 'RB')\n",
      "(',', ',')\n",
      "('there', 'EX')\n",
      "('are', 'VBP')\n",
      "('still', 'RB')\n",
      "('many', 'JJ')\n",
      "('defects', 'NNS')\n",
      "('in', 'IN')\n",
      "('the', 'DT')\n",
      "('all-inorganic', 'JJ')\n",
      "('perovskite', 'NN')\n",
      "('thin', 'JJ')\n",
      "('films', 'NNS')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('it', 'PRP')\n",
      "('is', 'VBZ')\n",
      "('difficult', 'JJ')\n",
      "('to', 'TO')\n",
      "('obtain', 'VB')\n",
      "('high', 'JJ')\n",
      "('power', 'NN')\n",
      "('conversion', 'NN')\n",
      "('efficiency', 'NN')\n",
      "('(', '(')\n",
      "('PCE', 'NNP')\n",
      "(')', ')')\n",
      "('.', '.')\n"
     ]
    }
   ],
   "source": [
    "# ---------------- EXTRA: Classificação Morfossintática (NLTK) --------------- #\n",
    "extra = corpora[0]\n",
    "doc = nltk.tokenize.sent_tokenize(extra)\n",
    "sent = nltk.tokenize.word_tokenize(doc[2])\n",
    "\n",
    "pos_tags = nltk.pos_tag(sent)\n",
    "for tag in pos_tags: print(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('PCE', 'ORGANIZATION')\n"
     ]
    }
   ],
   "source": [
    "# -------------- EXTRA: NER - Reconhecimento de entidade (spaCy) ------------- #\n",
    "tree = nltk.ne_chunk(pos_tags)\n",
    "\n",
    "# -------------------------- + Visualização gráfica -------------------------- #\n",
    "for subtree in tree:\n",
    "    if isinstance(subtree, nltk.Tree):\n",
    "        entity = ' '.join([word for word, tag in subtree.leaves()])\n",
    "        label = subtree.label()\n",
    "        print((entity, label))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
